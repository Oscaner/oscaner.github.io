<!DOCTYPE html>
<html lang="en">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    
    <meta name="baidu-site-verification" content="code-RlNzeiqm6B">
    
    
    <meta name="google-site-verification" content="clzGAgkJY2WD5IGr5G6KZS9xymJYL_IH2QIEettmobY">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="心若浮沉，浅笑安然">
    <meta name="keywords" content="Kang Oscaner China Blog">
    <meta name="theme-color" content="#000000">
    <meta name="site" content="https://www.oscaner.com/">

    <!-- Open Graph -->
    <meta property="og:title" content="[MLS-C01] [Data Engineering] Gathering data - Oscaner 的博客 | Oscaner Blog">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="Gathering data
">
    
    <meta property="article:published_time" content=" 2022-05-14T14:34:00Z">
    
    
    <meta property="article:author" content="Oscaner">
    
    
    <meta property="article:tag" content="Exam">
    
    <meta property="article:tag" content="AWS">
    
    <meta property="article:tag" content="MLS">
    
    <meta property="article:tag" content="Machine Learning">
    
    
    <meta property="og:image" content="https://q2.qlogo.cn/headimg_dl?bs=2573226076&dst_uin=2573226076&spec=640&url_enc=0&referer=bu_interface&term_type=PC">
    <meta property="og:url" content="https://www.oscaner.com/exam/aws/mls-c01/whizlabs/02-data-engineering/02-data-engineering.html">
    <meta property="og:site_name" content="Oscaner 的博客 | Oscaner Blog">

    <title>[MLS-C01] [Data Engineering] Gathering data - Oscaner 的博客 | Oscaner Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/assets/img/favicon.ico">

    <!-- Canonical URL -->
    <link rel="canonical" href="https://www.oscaner.com/exam/aws/mls-c01/whizlabs/02-data-engineering/02-data-engineering.html">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/assets/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/assets/css/hux-blog.min.css">
    <link rel="stylesheet" href="/assets/css/oscaner-blog.min.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <!-- <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <link href="/packages/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>

    <!-- Google AdSense -->
    <script data-ad-client="ca-pub-3286495153411959" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" crossorigin="anonymous"></script>

    <!-- MD5 -->
    <script src="/assets/js/md5.min.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-R9FFJYC4P1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-R9FFJYC4P1');
    </script>
    

</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->

    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">
                  
                    Oscaner
                  
                </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="huxblog_navbar">
                <div class="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="/">Home</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                        
                        
                        
                        
                        <li>
                            <a href="/friends/">Friends</a>
                        </li>
                        
                        
                        
                        
                        
                        <li>
                            <a href="/projects/">Projects</a>
                        </li>
                        
                        
                        
                        
                        
                        <li>
                            <a href="/archive/">Archive</a>
                        </li>
                        
                        
                        
                        
                        
                        <li class="search-icon">
                            <a href="javascript:void(0)">
                                <i class="fa fa-search"></i>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <script>
        // Drop Bootstarp low-performance Navbar
        // Use customize navbar with high-quality material design animation
        // in high-perf jank-free CSS3 implementation
        var $body = document.body;
        var $toggle = document.querySelector('.navbar-toggle');
        var $navbar = document.querySelector('#huxblog_navbar');
        var $collapse = document.querySelector('.navbar-collapse');

        var __HuxNav__ = {
            close: function () {
                $navbar.className = " ";
                // wait until animation end.
                setTimeout(function () {
                    // prevent frequently toggle
                    if ($navbar.className.indexOf('in') < 0) {
                        $collapse.style.height = "0px"
                    }
                }, 400)
            },
            open: function () {
                $collapse.style.height = "auto"
                $navbar.className += " in";
            }
        }

        // Bind Event
        $toggle.addEventListener('click', function (e) {
            if ($navbar.className.indexOf('in') > 0) {
                __HuxNav__.close()
            } else {
                __HuxNav__.open()
            }
        })

        /**
         * Since Fastclick is used to delegate 'touchstart' globally
         * to hack 300ms delay in iOS by performing a fake 'click',
         * Using 'e.stopPropagation' to stop 'touchstart' event from
         * $toggle/$collapse will break global delegation.
         *
         * Instead, we use a 'e.target' filter to prevent handler
         * added to document close HuxNav.
         *
         * Also, we use 'click' instead of 'touchstart' as compromise
         */
        document.addEventListener('click', function (e) {
            if (e.target == $toggle) return;
            if (e.target.className == 'icon-bar') return;
            __HuxNav__.close();
        })
    </script>

    <!-- Search -->
<div class="search-page">
  <div class="search-icon-close-container">
    <span class="search-icon-close">
      <i class="fa fa-chevron-down"></i>
    </span>
  </div>
  <div class="search-main container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <form></form>
        <input type="text" id="search-input" placeholder="$ grep...">
        
        <div id="search-results" class="mini-post-list"></div>
      </div>
    </div>
  </div>
</div>

    <!-- Image to hack wechat -->
<!-- <img src="/assets/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/assets/img/post-bg-alitrip.jpg" width="0" height="0"> -->

<!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/assets/img/post-bg-alitrip.jpg');
        background: ;
    }

    
</style>




<header class="intro-header">

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=Exam" title="Exam">Exam</a>
                        
                        <a class="tag" href="/archive/?tag=AWS" title="AWS">AWS</a>
                        
                        <a class="tag" href="/archive/?tag=MLS" title="MLS">MLS</a>
                        
                        <a class="tag" href="/archive/?tag=Machine+Learning" title="Machine Learning">Machine Learning</a>
                        
                    </div>
                    <h1>[MLS-C01] [Data Engineering] Gathering data</h1>
                    
                    <h2 class="subheading"></h2>
                    <span class="meta">Posted by Oscaner on May 14, 2022</span>
                </div>
            </div>
        </div>
    </div>
</header>







<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

                <h2 id="gathering-data">Gathering data</h2>

<h3 id="scikit-learn">Scikit-learn</h3>

<p>Retrieve data from Scikit-learn</p>

<p>Scikit-learn has many datasets for use in your modeling</p>

<p>Similar to the Kaggle and Reddit dataset repositories</p>

<p>https://scikit-learn.org/stable/datasets</p>

<h3 id="aws-services">AWS services</h3>

<p>Several AWS services to help gather data</p>

<ul>
  <li>Amazon Data Pipeline</li>
  <li>AWS Database Migration Service (DMS)</li>
  <li>AWS Glue</li>
  <li>Amazon SageMaker</li>
  <li>Amazon Athena</li>
</ul>

<h3 id="labs">Labs</h3>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/load_data_and_clean.ipynb" title="load_data_and_clean.ipynb" class="web-link">load_data_and_clean.ipynb</a></li>
</ul>

<h2 id="handling-missing-data">Handling Missing Data</h2>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/example-missing-data.png"></span></p>

<p>Several approaches to the problem of handling missing data</p>

<ul>
  <li>Do nothing</li>
  <li>Remove the entire record</li>
  <li>Mode/median/average value replacement</li>
  <li>Most frequent value</li>
  <li>Model-based imputation
    <ul>
      <li>K-Nearest Neighbors</li>
      <li>Regression</li>
      <li>Deep Learning</li>
    </ul>
  </li>
  <li>Interpolation / Extrapolation</li>
  <li>Forward filling / Backward filling</li>
  <li>Hot deck imputation</li>
</ul>

<h3 id="do-nothing">Do nothing</h3>

<p>Let your algorithm either replace them through imputation (XGBoost) or just ignore them as LightGBM does with its <code class="language-plaintext highlighter-rouge">use_missing=false</code> parameter</p>

<p>Some algorithms will throw an error if they find missing values (LinearRegression)</p>

<p>Or, replace all missing values</p>

<p>But with what ?</p>

<h3 id="remove-the-entire-record">Remove the Entire Record</h3>

<p>Remove the observations that have missing values</p>

<p>Risk losing data points with valuable information</p>

<h4 id="labs-1">Labs</h4>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/drop_features_with_missing_values.ipynb" title="drop_features_with_missing_values.ipynb" class="web-link">drop_features_with_missing_values.ipynb</a></li>
</ul>

<h3 id="medianaverage-value-replacement">Median/Average Value Replacement</h3>

<p>Replace the missing values with a simple median, or mean</p>

<ul>
  <li>Reflection of the other values in the feature</li>
  <li>Does’t factor correlation between features</li>
  <li>Can’t use on categorical features</li>
</ul>

<h4 id="labs-2">Labs</h4>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/impute_using_simpleimpute_mean.ipynb" title="impute_using_simpleimpute_mean.ipynb" class="web-link">impute_using_simpleimpute_mean.ipynb</a></li>
</ul>

<h3 id="most-frequent-value">Most Frequent Value</h3>

<p>Replace missing values with the most frequently occurring value in the feature</p>

<ul>
  <li>Doesn’t factor correlation between features</li>
  <li>Works with categorical features</li>
  <li>Can introduce bias into your model</li>
</ul>

<h3 id="model-based-imputation">Model-Based Imputation</h3>

<p>Use a machine learning algorithm to impute the missing values</p>

<ul>
  <li>K-Nearest Neighbors
    <ul>
      <li>Uses “feature similarity” to predict missing values</li>
    </ul>
  </li>
  <li>Regression
    <ul>
      <li>Predictors of the variable with missing values identified via correlation matrix</li>
      <li>Best predictors are selected and used as independent variables in a  regression equation</li>
      <li>Variable with missing data is used as the target variable</li>
    </ul>
  </li>
  <li>Deep Learning
    <ul>
      <li>Works very well with categorical and non-numerical features</li>
    </ul>
  </li>
</ul>

<h4 id="labs-3">Labs</h4>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/impute_using_k-nearest_neighbors.ipynb" title="impute_using_k-nearest_neighbors.ipynb" class="web-link">impute_using_k-nearest_neighbors.ipynb</a></li>
</ul>

<h3 id="other-methods">Other Methods</h3>

<ul>
  <li>Interpolation / Extrapolation
    <ul>
      <li>Estimate values from other observations within the range of a discrete set of known data points</li>
    </ul>
  </li>
  <li>Forward filling / Backward filling
    <ul>
      <li>Fill the missing value by filling it from the preceding value or the succeeding value</li>
    </ul>
  </li>
  <li>Hot deck imputation
    <ul>
      <li>Randomly choosing the missing value from a set of related and similar variables</li>
    </ul>
  </li>
</ul>

<h2 id="feature-selectionextraction">Feature Selection/Extraction</h2>

<h3 id="the-curse-of-dimensionality">The Curse of Dimensionality</h3>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/the-curse-of-dimensionality.png"></span></p>

<p>“Dimensionality” refers to the number of features (i.e. input variables) in your dataset</p>

<ul>
  <li>High feature to observation ratio causes some algorithms struggle to train effective models</li>
  <li>Visualization of <code class="language-plaintext highlighter-rouge">multi-dimensional datasets</code> vs <code class="language-plaintext highlighter-rouge">two or three-dimensions</code>
</li>
  <li>Two primary methods for reducing dimensionality: Feature Selection and Feature Extraction</li>
</ul>

<h3 id="feature-selection">Feature Selection</h3>

<p>Use feature selection to filter irrelevant or redundant features from your dataset</p>

<ul>
  <li>Feature Selection requires normalization</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-selection-requires-normalization.png"></span></p>

<ul>
  <li>Feature Selection removes features from your dataset - <strong>Variance Thresholds</strong>
</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-selection-removes-features.png"></span></p>

<h3 id="feature-extraction">Feature Extraction</h3>

<h4 id="requires-standardization">Requires Standardization</h4>

<ul>
  <li>Feature Extraction requires standardization</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-extraction-requires-standardization.png"></span></p>

<h4 id="reduces-features---retains-information">Reduces Features - Retains Information</h4>

<p>Creating new features from your existing features, feature extraction creates a new, smaller set of features that stills captures most of the useful information.</p>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-extraction-reduces-features.png"></span></p>

<h4 id="principal-component-analysis-pca">Principal Component Analysis (PCA)</h4>

<p><strong>Principal Component Analysis (PCA)</strong> is an unsupervised algorithm that creates new features by linearly combining original features</p>

<ul>
  <li>New features are uncorrelated, meaning they are orthogonal</li>
  <li>New features are ranked in order of “explained variance”.  The first principal component (PC1) explains the most variance in your dataset, PC2 explains the second-most variance, etc.
    <ul>
      <li>Explained variance tells you how much information (variance) can be attributed to each of the principal components</li>
      <li>You lose some of the variance (information) when you reduce your dimensional space</li>
    </ul>
  </li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/pca-example.png"></span></p>

<ul>
  <li>Principal component analysis (PCA) can be used to assist in visualization of your data</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/pca-visualization.png"></span></p>

<ul>
  <li>Principal component analysis (PCA) can also assist in speeding up your machine learning</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/pca-speeding-up-machine-learning.png"></span></p>

<h3 id="labs-4">Labs</h3>

<ul>
  <li>[feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds_-<em>lab_part_1.ipynb](https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds</em>-<em>lab_part_1.ipynb “feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds</em>-_lab_part_1.ipynb”)</li>
  <li>[feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds_-<em>lab_part_2.ipynb](https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds</em>-<em>lab_part_2.ipynb “feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds</em>-_lab_part_2.ipynb”)</li>
</ul>

<h2 id="encoding-categorical-values">Encoding categorical values</h2>

<ul>
  <li>Binarizer Encoding: for features of a binary nature</li>
  <li>Label Encoding: may imply ordinality, can use Ordinal Encoder</li>
  <li>One Hot Encoding: Change nominal categorical values such as “true”, “false”, or “rainy”, “sunny” to numerical values</li>
</ul>

<h3 id="labs-5">Labs</h3>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/encoding_categorical_values.ipynb" title="encoding_categorical_values.ipynb" class="web-link">encoding_categorical_values.ipynb</a></li>
</ul>

<h2 id="numerical-engineering">Numerical engineering</h2>

<ul>
  <li>Transform numeric values so machine learning algorithms can better analyze them</li>
  <li>Change numeric values so all values are on the same scale
    <ul>
      <li>Normalization: rescales the values into a range of <code class="language-plaintext highlighter-rouge">[0, 1]</code>
</li>
      <li>Standardization: rescales data to have a mean of 0 and a standard deviation of 1 (unit variance)</li>
    </ul>
  </li>
  <li>Binning</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/numerical-engineering-binning.png"></span></p>

<h3 id="binning">Binning</h3>

<p>AKA discretization or quantization</p>

<ul>
  <li>Categorical Binning
    <ul>
      <li>Group categorical values to gain insight into data: countries by geographical region</li>
    </ul>
  </li>
  <li>Numerical Binning
    <ul>
      <li>Divides continuous feature into a specified number of categories or bins, thus making the data discrete</li>
      <li>Reduces the number of discrete intervals of a continuous feature</li>
    </ul>
  </li>
  <li>Quantile Binning
    <ul>
      <li>Divide up data into equal sized bins</li>
      <li>Defines the bins using percentiles based on the distribution of the data</li>
    </ul>
  </li>
</ul>

<h3 id="labs-6">Labs</h3>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/numerical_engineering_34_26.ipynb" title="numerical_engineering_34_26.ipynb" class="web-link">numerical_engineering_34_26.ipynb</a></li>
</ul>

<h2 id="text-feature-editing">Text Feature Editing</h2>

<ul>
  <li>Transform text within data so machine learning algorithms can better analyze it</li>
  <li>Splitting text into smaller pieces</li>
  <li>Used for text analysis of documents, streamed dialog, etc.</li>
  <li>Can use in a pipeline as steps in a machine learning analysis</li>
</ul>

<h3 id="bag-of-words">Bag-of-Words</h3>

<ul>
  <li>Tokenizes raw text and creates a statistical representation of the text</li>
  <li>Breaks up text by whitespace into single words</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/bag-of-words.png"></span></p>

<h3 id="n-gram">N-Gram</h3>

<ul>
  <li>Extension of Bag-of-Words which produces groups of words of n size</li>
  <li>Breaks up text by whitespace into groups of words</li>
</ul>

<p><span class="embed-image-wrapper"><img class="embed-image" src="/assets/img/in-post/exam/aws/mls-c01/whizlabs/n-gram.png"></span></p>

<h3 id="orthogonal-sparse-bigram">Orthogonal Sparse Bigram</h3>

<ul>
  <li>Creates groups of words of size n, returns every pair of words that includes the first word</li>
  <li>Creates groups of words that always include the first word</li>
</ul>

<h3 id="tf-idf">TF-IDF</h3>

<ul>
  <li>Term Frequency-Inverse Document Frequency (TF-IDF)</li>
  <li>Shows how important a word or words are to a given set of text by providing appropriate weights to terms that are common and less common</li>
  <li>Show the popularity of a word or words in text data by making common words like “the” or “and” less important</li>
</ul>

<h3 id="use-cases">Use Cases</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Use Case</th>
      <th style="text-align: center">Transformation</th>
      <th style="text-align: left">Reason</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Finding phrases in spam</td>
      <td style="text-align: center">N-Gram</td>
      <td style="text-align: left">Compare whole phrases such as “you’re a winner!” or “Buy now!”</td>
    </tr>
    <tr>
      <td style="text-align: center">Finding subject of several PDFs</td>
      <td style="text-align: center">TF-IDF<br>Orthogonal Sparse Bigram</td>
      <td style="text-align: left">Filter less important words in the documents.<br>Find common word combinations repeated in the documents.</td>
    </tr>
  </tbody>
</table>

<h3 id="labs-7">Labs</h3>

<ul>
  <li><a href="https://github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/text_feature_editing.ipynb" title="text_feature_editing.ipynb" class="web-link">text_feature_editing.ipynb</a></li>
</ul>



                <!-- Copyright Notice -->
                
<hr>

<p>
  本文由
  <a href="/about/" target="_blank">
    Oscaner
  </a> 创作, 采用
  <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="external nofollow">
    知识共享署名4.0
  </a> 国际许可协议进行许可 <br>
  本站文章除注明转载/出处外, 均为本站原创或翻译, 转载前请务必署名
</p>


                

                <hr>
<hr style="visibility: hidden;">

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/exam/aws/mls-c01/whizlabs/02-data-engineering/01-introduction.html" data-toggle="tooltip" data-placement="top" title="[MLS-C01] [Data Engineering] Introduction">
                        Previous<br>
                        <span>[MLS-C01] [Data Engineering] Introduction</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/exam/aws/mls-c01/whizlabs/02-data-engineering/03-aws-migration-services.html" data-toggle="tooltip" data-placement="top" title="[MLS-C01] [Data Engineering] AWS Migration services">
                        Next<br>
                        <span>[MLS-C01] [Data Engineering] AWS Migration services</span>
                        </a>
                    </li>
                    
                </ul>
                <hr style="visibility: hidden;">

                <!-- Comment start -->
<div class="comment">
  

  
  <!-- gitalk 评论框 start -->
  <div id="gitalk-container"></div>
  <!-- gitalk 评论框 end -->
  

  
</div>
<!-- Comment end -->






<!-- Gitalk CSS -->
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<!-- gitalk 公共JS代码 start (一个网页只需插入一次) -->
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script type="text/javascript">
  function getLangForGitalk() {
    lang = new URLSearchParams(document.location.search).get("lang");
    return lang == 'zh' ? 'zh-CN' : lang;
  }

  var body = location.href;

  var subtitle = "";
  if (subtitle) {
    body += "\n" + subtitle;
  }

  var description = "";
  if (description) {
    body += "\n" + description;
  }

  var gitalk = new Gitalk({
      clientID: 'f86fb5601466c278f223',
      clientSecret: '8234184af9a4cbc9dfa58bbea7ff6cdb84d33f1f',
      repo: 'oscaner.github.io',
      owner: 'Oscaner',
      admin: 'Oscaner',
      labels: 'Gitalk|Exam|AWS|MLS|Machine Learning|Oscaner'.split('|'),
      body: body,
      language: getLangForGitalk() ? getLangForGitalk() : 'zh-CN',

      id: MD5('/exam/aws/mls-c01/whizlabs/02-data-engineering/02-data-engineering.html'),
      // facebook-like distraction free mode
      distractionFreeMode: true
  });

  gitalk.render('gitalk-container');
</script>
<!-- gitalk 公共JS代码 end -->





            </div>

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                


<section>
    
        <hr class="hidden-sm hidden-xs">
    
    <h5><a href="/archive/">FEATURED TAGS</a></h5>
    <div class="tags">
        
        
        
        
        
        
                <a data-sort="0040" href="/archive/?tag=Skill" title="Skill" rel="95">Skill</a>
        
                <a data-sort="0097" href="/archive/?tag=Clang" title="Clang" rel="38">Clang</a>
        
                <a data-sort="0097" href="/archive/?tag=Exam" title="Exam" rel="38">Exam</a>
        
                <a data-sort="0098" href="/archive/?tag=AWS" title="AWS" rel="37">AWS</a>
        
                <a data-sort="0098" href="/archive/?tag=C%2B%2B" title="C++" rel="37">C++</a>
        
                <a data-sort="0098" href="/archive/?tag=Data+Structure" title="Data Structure" rel="37">Data Structure</a>
        
                <a data-sort="0099" href="/archive/?tag=MLS" title="MLS" rel="36">MLS</a>
        
                <a data-sort="0099" href="/archive/?tag=Machine+Learning" title="Machine Learning" rel="36">Machine Learning</a>
        
                <a data-sort="0122" href="/archive/?tag=PHP" title="PHP" rel="13">PHP</a>
        
                <a data-sort="0124" href="/archive/?tag=Coding" title="Coding" rel="11">Coding</a>
        
                <a data-sort="0124" href="/archive/?tag=Others" title="Others" rel="11">Others</a>
        
                <a data-sort="0125" href="/archive/?tag=Graduate" title="Graduate" rel="10">Graduate</a>
        
                <a data-sort="0125" href="/archive/?tag=Math" title="Math" rel="10">Math</a>
        
                <a data-sort="0126" href="/archive/?tag=NoSQL" title="NoSQL" rel="9">NoSQL</a>
        
                <a data-sort="0129" href="/archive/?tag=SQL" title="SQL" rel="6">SQL</a>
        
                <a data-sort="0130" href="/archive/?tag=Linux" title="Linux" rel="5">Linux</a>
        
                <a data-sort="0130" href="/archive/?tag=Redis" title="Redis" rel="5">Redis</a>
        
                <a data-sort="0132" href="/archive/?tag=Fibonacci" title="Fibonacci" rel="3">Fibonacci</a>
        
                <a data-sort="0132" href="/archive/?tag=Git" title="Git" rel="3">Git</a>
        
                <a data-sort="0132" href="/archive/?tag=Memcached" title="Memcached" rel="3">Memcached</a>
        
                <a data-sort="0133" href="/archive/?tag=MySQL" title="MySQL" rel="2">MySQL</a>
    </div>
</section>


                <!-- Friends Blog -->
                
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
  <li><a href="https://asdrt666.com" target="_blank" rel="friend">Asdrt</a></li>
  
  <li><a href="https://szdblog.com" target="_blank" rel="friend">Choba·乔巴博客</a></li>
  
  <li><a href="https://ibcl.us/" target="_blank" rel="friend">I BCL.</a></li>
  
  <li><a href="https://www.wmathor.com/" target="_blank" rel="friend">mathor</a></li>
  
  <li><a href="https://tongtaos.com" target="_blank" rel="friend">Mr. 童的博客</a></li>
  
  <li><a href="https://blog.kejijie.vip/" target="_blank" rel="friend">wantsget</a></li>
  
  <li><a href="https://o0o0o0.cn/" target="_blank" rel="friend">三十三言</a></li>
  
  <li><a href="http://www.gazyip.cn/" target="_blank" rel="friend">八个比特</a></li>
  
  <li><a href="https://www.lixuejiang.com/" target="_blank" rel="friend">李学江博客</a></li>
  
  <li><a href="https://5sir.cn" target="_blank" rel="friend">梁Sir的小站</a></li>
  
  <li><a href="http://isenchun.cn/" target="_blank" rel="friend">森纯个人博客</a></li>
  
  <li><a href="http://www.nothamor.cn/" target="_blank" rel="friend">欧尼酱</a></li>
  
  <li><a href="https://www.lkxin.cn" target="_blank" rel="friend">清酒踏月</a></li>
  
  <li><a href="https://www.yyhy.me" target="_blank" rel="friend">烟雨寒云博客</a></li>
  
  <li><a href="http://mlldxe.cn" target="_blank" rel="friend">犬の窝</a></li>
  
  <li><a href="https://aoppp.com" target="_blank" rel="friend">憧憬播客</a></li>
  
</ul>



                <!-- Ads -->
                <hr>

<!-- <script async
  src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3286495153411959"
  crossorigin="anonymous"></script> -->

<!-- Oscaner's Vertical Ad -->

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3286495153411959" data-ad-slot="2277392638" data-ad-format="auto" data-full-width-responsive="true"></ins>



<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

            </div>
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async('/packages/anchor/1.1.1/anchor.min.js', function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<!-- SEO -->
<!-- Schema Markup -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "[MLS-C01] [Data Engineering] Gathering data",
  "author": {
    "@type": "Person",
    "name": "Oscaner"
  },
  "datePublished": "May 14, 2022",
  "image": "https://www.oscaner.com/assets/img/post-bg-alitrip.jpg",
  "articleBody": "&lt;h2 id=&quot;gathering-data&quot;&gt;Gathering data&lt;/h2&gt;\n\n&lt;h3 id=&quot;scikit-learn&quot;&gt;Scikit-learn&lt;/h3&gt;\n\n&lt;p&gt;Retrieve data from Scikit-learn&lt;/p&gt;\n\n&lt;p&gt;Scikit-learn has many datasets for use in your modeling&lt;/p&gt;\n\n&lt;p&gt;Similar to the Kaggle and Reddit dataset repositories&lt;/p&gt;\n\n&lt;p&gt;https&#58;//scikit-learn.org/stable/datasets&lt;/p&gt;\n\n&lt;h3 id=&quot;aws-services&quot;&gt;AWS services&lt;/h3&gt;\n\n&lt;p&gt;Several AWS services to help gather data&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Amazon Data Pipeline&lt;/li&gt;\n  &lt;li&gt;AWS Database Migration Service (DMS)&lt;/li&gt;\n  &lt;li&gt;AWS Glue&lt;/li&gt;\n  &lt;li&gt;Amazon SageMaker&lt;/li&gt;\n  &lt;li&gt;Amazon Athena&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;labs&quot;&gt;Labs&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/load_data_and_clean.ipynb&quot; title=&quot;load_data_and_clean.ipynb&quot; class=&quot;web-link&quot;&gt;load_data_and_clean.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2 id=&quot;handling-missing-data&quot;&gt;Handling Missing Data&lt;/h2&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/example-missing-data.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;p&gt;Several approaches to the problem of handling missing data&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Do nothing&lt;/li&gt;\n  &lt;li&gt;Remove the entire record&lt;/li&gt;\n  &lt;li&gt;Mode/median/average value replacement&lt;/li&gt;\n  &lt;li&gt;Most frequent value&lt;/li&gt;\n  &lt;li&gt;Model-based imputation\n    &lt;ul&gt;\n      &lt;li&gt;K-Nearest Neighbors&lt;/li&gt;\n      &lt;li&gt;Regression&lt;/li&gt;\n      &lt;li&gt;Deep Learning&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Interpolation / Extrapolation&lt;/li&gt;\n  &lt;li&gt;Forward filling / Backward filling&lt;/li&gt;\n  &lt;li&gt;Hot deck imputation&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;do-nothing&quot;&gt;Do nothing&lt;/h3&gt;\n\n&lt;p&gt;Let your algorithm either replace them through imputation (XGBoost) or just ignore them as LightGBM does with its &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use_missing=false&lt;/code&gt; parameter&lt;/p&gt;\n\n&lt;p&gt;Some algorithms will throw an error if they find missing values (LinearRegression)&lt;/p&gt;\n\n&lt;p&gt;Or, replace all missing values&lt;/p&gt;\n\n&lt;p&gt;But with what ?&lt;/p&gt;\n\n&lt;h3 id=&quot;remove-the-entire-record&quot;&gt;Remove the Entire Record&lt;/h3&gt;\n\n&lt;p&gt;Remove the observations that have missing values&lt;/p&gt;\n\n&lt;p&gt;Risk losing data points with valuable information&lt;/p&gt;\n\n&lt;h4 id=&quot;labs-1&quot;&gt;Labs&lt;/h4&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/drop_features_with_missing_values.ipynb&quot; title=&quot;drop_features_with_missing_values.ipynb&quot; class=&quot;web-link&quot;&gt;drop_features_with_missing_values.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;medianaverage-value-replacement&quot;&gt;Median/Average Value Replacement&lt;/h3&gt;\n\n&lt;p&gt;Replace the missing values with a simple median, or mean&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Reflection of the other values in the feature&lt;/li&gt;\n  &lt;li&gt;Does’t factor correlation between features&lt;/li&gt;\n  &lt;li&gt;Can’t use on categorical features&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h4 id=&quot;labs-2&quot;&gt;Labs&lt;/h4&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/impute_using_simpleimpute_mean.ipynb&quot; title=&quot;impute_using_simpleimpute_mean.ipynb&quot; class=&quot;web-link&quot;&gt;impute_using_simpleimpute_mean.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;most-frequent-value&quot;&gt;Most Frequent Value&lt;/h3&gt;\n\n&lt;p&gt;Replace missing values with the most frequently occurring value in the feature&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Doesn’t factor correlation between features&lt;/li&gt;\n  &lt;li&gt;Works with categorical features&lt;/li&gt;\n  &lt;li&gt;Can introduce bias into your model&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;model-based-imputation&quot;&gt;Model-Based Imputation&lt;/h3&gt;\n\n&lt;p&gt;Use a machine learning algorithm to impute the missing values&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;K-Nearest Neighbors\n    &lt;ul&gt;\n      &lt;li&gt;Uses “feature similarity” to predict missing values&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Regression\n    &lt;ul&gt;\n      &lt;li&gt;Predictors of the variable with missing values identified via correlation matrix&lt;/li&gt;\n      &lt;li&gt;Best predictors are selected and used as independent variables in a  regression equation&lt;/li&gt;\n      &lt;li&gt;Variable with missing data is used as the target variable&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Deep Learning\n    &lt;ul&gt;\n      &lt;li&gt;Works very well with categorical and non-numerical features&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h4 id=&quot;labs-3&quot;&gt;Labs&lt;/h4&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/impute_using_k-nearest_neighbors.ipynb&quot; title=&quot;impute_using_k-nearest_neighbors.ipynb&quot; class=&quot;web-link&quot;&gt;impute_using_k-nearest_neighbors.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;other-methods&quot;&gt;Other Methods&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Interpolation / Extrapolation\n    &lt;ul&gt;\n      &lt;li&gt;Estimate values from other observations within the range of a discrete set of known data points&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Forward filling / Backward filling\n    &lt;ul&gt;\n      &lt;li&gt;Fill the missing value by filling it from the preceding value or the succeeding value&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Hot deck imputation\n    &lt;ul&gt;\n      &lt;li&gt;Randomly choosing the missing value from a set of related and similar variables&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2 id=&quot;feature-selectionextraction&quot;&gt;Feature Selection/Extraction&lt;/h2&gt;\n\n&lt;h3 id=&quot;the-curse-of-dimensionality&quot;&gt;The Curse of Dimensionality&lt;/h3&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/the-curse-of-dimensionality.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;p&gt;“Dimensionality” refers to the number of features (i.e. input variables) in your dataset&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;High feature to observation ratio causes some algorithms struggle to train effective models&lt;/li&gt;\n  &lt;li&gt;Visualization of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;multi-dimensional datasets&lt;/code&gt; vs &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;two or three-dimensions&lt;/code&gt;\n&lt;/li&gt;\n  &lt;li&gt;Two primary methods for reducing dimensionality&#58; Feature Selection and Feature Extraction&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;feature-selection&quot;&gt;Feature Selection&lt;/h3&gt;\n\n&lt;p&gt;Use feature selection to filter irrelevant or redundant features from your dataset&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Feature Selection requires normalization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-selection-requires-normalization.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Feature Selection removes features from your dataset - &lt;strong&gt;Variance Thresholds&lt;/strong&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-selection-removes-features.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h3 id=&quot;feature-extraction&quot;&gt;Feature Extraction&lt;/h3&gt;\n\n&lt;h4 id=&quot;requires-standardization&quot;&gt;Requires Standardization&lt;/h4&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Feature Extraction requires standardization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-extraction-requires-standardization.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h4 id=&quot;reduces-features---retains-information&quot;&gt;Reduces Features - Retains Information&lt;/h4&gt;\n\n&lt;p&gt;Creating new features from your existing features, feature extraction creates a new, smaller set of features that stills captures most of the useful information.&lt;/p&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/feature-extraction-reduces-features.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h4 id=&quot;principal-component-analysis-pca&quot;&gt;Principal Component Analysis (PCA)&lt;/h4&gt;\n\n&lt;p&gt;&lt;strong&gt;Principal Component Analysis (PCA)&lt;/strong&gt; is an unsupervised algorithm that creates new features by linearly combining original features&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;New features are uncorrelated, meaning they are orthogonal&lt;/li&gt;\n  &lt;li&gt;New features are ranked in order of “explained variance”.  The first principal component (PC1) explains the most variance in your dataset, PC2 explains the second-most variance, etc.\n    &lt;ul&gt;\n      &lt;li&gt;Explained variance tells you how much information (variance) can be attributed to each of the principal components&lt;/li&gt;\n      &lt;li&gt;You lose some of the variance (information) when you reduce your dimensional space&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/pca-example.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Principal component analysis (PCA) can be used to assist in visualization of your data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/pca-visualization.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Principal component analysis (PCA) can also assist in speeding up your machine learning&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/pca-speeding-up-machine-learning.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h3 id=&quot;labs-4&quot;&gt;Labs&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;[feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds_-&lt;em&gt;lab_part_1.ipynb](https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds&lt;/em&gt;-&lt;em&gt;lab_part_1.ipynb “feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds&lt;/em&gt;-_lab_part_1.ipynb”)&lt;/li&gt;\n  &lt;li&gt;[feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds_-&lt;em&gt;lab_part_2.ipynb](https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds&lt;/em&gt;-&lt;em&gt;lab_part_2.ipynb “feature_extraction_and_feature_selection_with_principal_component_analysis_and_variance_thresholds&lt;/em&gt;-_lab_part_2.ipynb”)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2 id=&quot;encoding-categorical-values&quot;&gt;Encoding categorical values&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Binarizer Encoding&#58; for features of a binary nature&lt;/li&gt;\n  &lt;li&gt;Label Encoding&#58; may imply ordinality, can use Ordinal Encoder&lt;/li&gt;\n  &lt;li&gt;One Hot Encoding&#58; Change nominal categorical values such as “true”, “false”, or “rainy”, “sunny” to numerical values&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;labs-5&quot;&gt;Labs&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/encoding_categorical_values.ipynb&quot; title=&quot;encoding_categorical_values.ipynb&quot; class=&quot;web-link&quot;&gt;encoding_categorical_values.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2 id=&quot;numerical-engineering&quot;&gt;Numerical engineering&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Transform numeric values so machine learning algorithms can better analyze them&lt;/li&gt;\n  &lt;li&gt;Change numeric values so all values are on the same scale\n    &lt;ul&gt;\n      &lt;li&gt;Normalization&#58; rescales the values into a range of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[0, 1]&lt;/code&gt;\n&lt;/li&gt;\n      &lt;li&gt;Standardization&#58; rescales data to have a mean of 0 and a standard deviation of 1 (unit variance)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Binning&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/numerical-engineering-binning.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h3 id=&quot;binning&quot;&gt;Binning&lt;/h3&gt;\n\n&lt;p&gt;AKA discretization or quantization&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Categorical Binning\n    &lt;ul&gt;\n      &lt;li&gt;Group categorical values to gain insight into data&#58; countries by geographical region&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Numerical Binning\n    &lt;ul&gt;\n      &lt;li&gt;Divides continuous feature into a specified number of categories or bins, thus making the data discrete&lt;/li&gt;\n      &lt;li&gt;Reduces the number of discrete intervals of a continuous feature&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Quantile Binning\n    &lt;ul&gt;\n      &lt;li&gt;Divide up data into equal sized bins&lt;/li&gt;\n      &lt;li&gt;Defines the bins using percentiles based on the distribution of the data&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;labs-6&quot;&gt;Labs&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/numerical_engineering_34_26.ipynb&quot; title=&quot;numerical_engineering_34_26.ipynb&quot; class=&quot;web-link&quot;&gt;numerical_engineering_34_26.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2 id=&quot;text-feature-editing&quot;&gt;Text Feature Editing&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Transform text within data so machine learning algorithms can better analyze it&lt;/li&gt;\n  &lt;li&gt;Splitting text into smaller pieces&lt;/li&gt;\n  &lt;li&gt;Used for text analysis of documents, streamed dialog, etc.&lt;/li&gt;\n  &lt;li&gt;Can use in a pipeline as steps in a machine learning analysis&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;bag-of-words&quot;&gt;Bag-of-Words&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Tokenizes raw text and creates a statistical representation of the text&lt;/li&gt;\n  &lt;li&gt;Breaks up text by whitespace into single words&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/bag-of-words.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h3 id=&quot;n-gram&quot;&gt;N-Gram&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Extension of Bag-of-Words which produces groups of words of n size&lt;/li&gt;\n  &lt;li&gt;Breaks up text by whitespace into groups of words&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;span class=&quot;embed-image-wrapper&quot;&gt;&lt;img class=&quot;embed-image&quot; src=&quot;/assets/img/in-post/exam/aws/mls-c01/whizlabs/n-gram.png&quot;&gt;&lt;/span&gt;&lt;/p&gt;\n\n&lt;h3 id=&quot;orthogonal-sparse-bigram&quot;&gt;Orthogonal Sparse Bigram&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Creates groups of words of size n, returns every pair of words that includes the first word&lt;/li&gt;\n  &lt;li&gt;Creates groups of words that always include the first word&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;tf-idf&quot;&gt;TF-IDF&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Term Frequency-Inverse Document Frequency (TF-IDF)&lt;/li&gt;\n  &lt;li&gt;Shows how important a word or words are to a given set of text by providing appropriate weights to terms that are common and less common&lt;/li&gt;\n  &lt;li&gt;Show the popularity of a word or words in text data by making common words like “the” or “and” less important&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;use-cases&quot;&gt;Use Cases&lt;/h3&gt;\n\n&lt;table&gt;\n  &lt;thead&gt;\n    &lt;tr&gt;\n      &lt;th style=&quot;text-align&#58; center&quot;&gt;Use Case&lt;/th&gt;\n      &lt;th style=&quot;text-align&#58; center&quot;&gt;Transformation&lt;/th&gt;\n      &lt;th style=&quot;text-align&#58; left&quot;&gt;Reason&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody&gt;\n    &lt;tr&gt;\n      &lt;td style=&quot;text-align&#58; center&quot;&gt;Finding phrases in spam&lt;/td&gt;\n      &lt;td style=&quot;text-align&#58; center&quot;&gt;N-Gram&lt;/td&gt;\n      &lt;td style=&quot;text-align&#58; left&quot;&gt;Compare whole phrases such as &quot;you’re a winner!&quot; or &quot;Buy now!&quot;&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td style=&quot;text-align&#58; center&quot;&gt;Finding subject of several PDFs&lt;/td&gt;\n      &lt;td style=&quot;text-align&#58; center&quot;&gt;TF-IDF&lt;br&gt;Orthogonal Sparse Bigram&lt;/td&gt;\n      &lt;td style=&quot;text-align&#58; left&quot;&gt;Filter less important words in the documents.&lt;br&gt;Find common word combinations repeated in the documents.&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tbody&gt;\n&lt;/table&gt;\n\n&lt;h3 id=&quot;labs-7&quot;&gt;Labs&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;a href=&quot;https&#58;//github.com/Oscaner/Exam/blob/master/aws/mls-c01/whizlabs/code/02-data-engineering/text_feature_editing.ipynb&quot; title=&quot;text_feature_editing.ipynb&quot; class=&quot;web-link&quot;&gt;text_feature_editing.ipynb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n",
  "url": "https://www.oscaner.com/exam/aws/mls-c01/whizlabs/02-data-engineering/02-data-engineering.html"
}
</script>




    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                


<ul class="list-inline text-center">


  
  
  
  <li>
    <a target="_blank" href="https://www.zhihu.com/people/oscaner">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa  fa-stack-1x fa-inverse">知</i>
      </span>
    </a>
  </li>
  
  
  <li>
    <a target="_blank" href="http://weibo.com/Oscaner">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  
  <li>
    <a target="_blank" href="https://github.com/Oscaner">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  
  <li>
    <a target="_blank" href="https://space.bilibili.com/17118231">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-stack-1x fa-inverse iconfont icon-bilibili-fill"></i>
      </span>
    </a>
  </li>
  
</ul>


                <p class="copyright text-muted">
                    Copyright © Oscaner 2023
                    <a href="https://beian.miit.gov.cn" target="_blank">浙ICP备17039697号-2</a>
                    <br>
                    Powered by <a href="https://www.oscaner.com">Oscaner Blog</a> |
                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px" height="20px" src="https://ghbtns.com/github-btn.html?user=oscaner&repo=oscaner.github.io&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/assets/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/assets/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/assets/js/hux-blog.min.js"></script>

<!-- Simple Jekyll Search -->
<script src="/assets/js/simple-jekyll-search.min.js"></script>

<!-- Service Worker -->

<script src="/assets/js/snackbar.js"></script>
<script src="/assets/js/sw-registration.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->







<!--fastClick.js -->
<script>
    async('/packages/fastclick/1.0.6/fastclick.min.js', function () {
        var $nav = document.querySelector("nav");
        if ($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->

<script>
    // dynamic User by Oscaner
    var _gaId = '';
    var _gaDomain = 'www.oscaner.com';

    // Originial
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>


<!-- Baidu Tongji -->

<script>
    // dynamic User by Oscaner
    var _baId = 'd9c74d9266af4d68f376f0fb9d5fb71c';

    // Originial
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?" + _baId;
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog(selector) {

        // interop with multilangual
        if ('false' == 'true') {
            _containerSelector = 'div.post-container.active';
        } else {
            _containerSelector = 'div.post-container';
        }

        if (!$(_containerSelector).length) {
            _containerSelector = 'div.post-container';
        }

        // init
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/assets/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->


<!-- Simple Jekyll Search -->
<script>
    // https://stackoverflow.com/questions/1912501/unescape-html-entities-in-javascript
    function htmlDecode(input) {
        var e = document.createElement('textarea');
        e.innerHTML = input;
        // handle case of empty input
        return e.childNodes.length === 0 ? "" : e.childNodes[0].nodeValue;
    }

    SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('search-results'),
        json: '/search.json',
        searchResultTemplate: '<div class="post-preview item"><a href="{url}"><h2 class="post-title">{title}</h2><h3 class="post-subtitle">{subtitle}</h3><hr></a></div>',
        noResultsText: 'No results',
        limit: 50,
        fuzzy: false,
        // a hack to get escaped subtitle unescaped. for some reason,
        // post.subtitle w/o escape filter nuke entire search.
        templateMiddleware: function (prop, value, template) {
            if (prop === 'subtitle' || prop === 'title') {
                if (value.indexOf("code")) {
                    return htmlDecode(value);
                } else {
                    return value;
                }
            }
        }
    });

    $(document).ready(function () {
        var $searchPage = $('.search-page');
        var $searchOpen = $('.search-icon');
        var $searchClose = $('.search-icon-close');
        var $searchInput = $('#search-input');
        var $body = $('body');

        $searchOpen.on('click', function (e) {
            e.preventDefault();
            $searchPage.toggleClass('search-active');
            var prevClasses = $body.attr('class') || '';
            setTimeout(function () {
                $body.addClass('no-scroll');
            }, 400)

            if ($searchPage.hasClass('search-active')) {
                $searchClose.on('click', function (e) {
                    e.preventDefault();
                    $searchPage.removeClass('search-active');
                    $body.attr('class', prevClasses);  // from closure
                });
                $searchInput.focus();
            }
        });
    });
</script>



<!-- Image to hack wechat -->
<img src="/assets/img/icon_wechat.png" width="0" height="0">
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
